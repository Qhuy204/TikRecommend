{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ba29821",
   "metadata": {},
   "source": [
    "ðŸ“Š Intelligent Recommendation System - Analysis & Visualization\n",
    " \n",
    " Notebook nÃ y giÃºp báº¡n:\n",
    " 1. Explore dá»¯ liá»‡u TikDataset\n",
    " 2. Visualize káº¿t quáº£ preprocessing\n",
    " 3. Analyze model performance\n",
    " 4. Experiment vá»›i recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c3d028",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49993c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Check data files\n",
    "print(\"Checking data files...\")\n",
    "files = {\n",
    "    \"Item Features\": \"data/processed/item_features.csv\",\n",
    "    \"Ranking Features\": \"data/processed/ranking_features.csv\",\n",
    "    \"Interactions\": \"data/processed/interactions.csv\"\n",
    "}\n",
    "\n",
    "for name, path in files.items():\n",
    "    exists = \"âœ“\" if Path(path).exists() else \"âœ—\"\n",
    "    print(f\"{exists} {name}: {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e676490",
   "metadata": {},
   "source": [
    "## 2. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3741d3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "item_df = pd.read_csv(\"data/processed/item_features.csv\")\n",
    "ranking_df = pd.read_csv(\"data/processed/ranking_features.csv\")\n",
    "\n",
    "# Basic info\n",
    "print(\"=\"*60)\n",
    "print(\"DATASET OVERVIEW\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nItems: {len(item_df):,}\")\n",
    "print(f\"Ranking samples: {len(ranking_df):,}\")\n",
    "print(f\"\\nCategories: {item_df['category'].nunique():,}\")\n",
    "print(f\"Brands: {item_df['brand_id'].nunique():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7225b293",
   "metadata": {},
   "source": [
    "### 2.1. Category Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b68b0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top categories\n",
    "top_categories = item_df['category'].value_counts().head(20)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "top_categories.plot(kind='barh', color='steelblue')\n",
    "plt.title('Top 20 Categories by Product Count', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Number of Products')\n",
    "plt.ylabel('Category')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 10 Categories:\")\n",
    "print(top_categories.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb04c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category distribution pie chart\n",
    "top_10_cats = item_df['category'].value_counts().head(10)\n",
    "other_count = len(item_df) - top_10_cats.sum()\n",
    "\n",
    "# Add \"Others\"\n",
    "plot_data = pd.concat([top_10_cats, pd.Series({'Others': other_count})])\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.pie(plot_data, labels=plot_data.index, autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Product Distribution by Category', fontsize=14, fontweight='bold')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873fe724",
   "metadata": {},
   "source": [
    "### 2.2. Price Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8b4b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price distribution\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "# Remove outliers for better visualization\n",
    "price_filtered = ranking_df[ranking_df['price'] < ranking_df['price'].quantile(0.95)]\n",
    "plt.hist(price_filtered['price'], bins=50, color='skyblue', edgecolor='black')\n",
    "plt.xlabel('Price (VNÄ)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Price Distribution (95th percentile)', fontweight='bold')\n",
    "plt.ticklabel_format(style='plain', axis='x')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "# Log scale\n",
    "plt.hist(np.log10(ranking_df['price'].replace(0, 1)), bins=50, color='salmon', edgecolor='black')\n",
    "plt.xlabel('Log10(Price)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Price Distribution (Log Scale)', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Price statistics\n",
    "print(\"\\nPrice Statistics:\")\n",
    "print(ranking_df['price'].describe())\n",
    "print(f\"\\nNumber of unique prices: {ranking_df['price'].nunique():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c341ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price by category (top 10)\n",
    "top_cats = item_df['category'].value_counts().head(10).index\n",
    "price_by_cat = ranking_df.merge(\n",
    "    item_df[['product_id', 'category']], \n",
    "    on='product_id'\n",
    ")[['category', 'price']]\n",
    "\n",
    "price_by_cat = price_by_cat[price_by_cat['category'].isin(top_cats)]\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.boxplot(data=price_by_cat, x='category', y='price', palette='Set2')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel('Price (VNÄ)')\n",
    "plt.title('Price Distribution by Top Categories', fontsize=14, fontweight='bold')\n",
    "plt.ticklabel_format(style='plain', axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79108bac",
   "metadata": {},
   "source": [
    "### 2.3. Rating Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1d7c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rating distribution\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "rating_counts = ranking_df['rating_average'].value_counts().sort_index()\n",
    "plt.bar(rating_counts.index, rating_counts.values, color='gold', edgecolor='black')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Number of Products')\n",
    "plt.title('Rating Distribution', fontweight='bold')\n",
    "plt.xticks([0, 1, 2, 3, 4, 5])\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "# Rating vs Review Count\n",
    "sample = ranking_df.sample(min(5000, len(ranking_df)))\n",
    "plt.scatter(sample['review_count'], sample['rating_average'], \n",
    "           alpha=0.3, s=10, color='purple')\n",
    "plt.xlabel('Review Count')\n",
    "plt.ylabel('Rating Average')\n",
    "plt.title('Rating vs Review Count', fontweight='bold')\n",
    "plt.xscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Rating statistics\n",
    "print(\"\\nRating Statistics:\")\n",
    "print(ranking_df['rating_average'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfa0099",
   "metadata": {},
   "source": [
    "### 2.4. Discount Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847d9132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discount rate distribution\n",
    "has_discount = ranking_df[ranking_df['discount_rate'] > 0]\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(has_discount['discount_rate'], bins=30, color='green', alpha=0.7, edgecolor='black')\n",
    "plt.xlabel('Discount Rate (%)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title(f'Discount Distribution ({len(has_discount):,} products)', fontweight='bold')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "# Discount ranges\n",
    "discount_ranges = pd.cut(\n",
    "    ranking_df['discount_rate'], \n",
    "    bins=[0, 10, 20, 30, 50, 100],\n",
    "    labels=['0-10%', '10-20%', '20-30%', '30-50%', '50%+']\n",
    ")\n",
    "discount_counts = discount_ranges.value_counts().sort_index()\n",
    "plt.pie(discount_counts, labels=discount_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Discount Range Distribution', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nProducts with discount: {len(has_discount):,} ({len(has_discount)/len(ranking_df)*100:.1f}%)\")\n",
    "print(f\"Average discount: {has_discount['discount_rate'].mean():.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db03588d",
   "metadata": {},
   "source": [
    "### 2.5. Badge Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee650075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Badge counts\n",
    "badges = {\n",
    "    'Authentic': ranking_df['is_authentic'].sum(),\n",
    "    'FreeShip': ranking_df['is_freeship'].sum(),\n",
    "    'Return Policy': ranking_df['has_return_policy'].sum(),\n",
    "    'Available': ranking_df['is_available'].sum()\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(badges.keys(), badges.values(), color=['gold', 'skyblue', 'lightgreen', 'salmon'])\n",
    "plt.ylabel('Number of Products')\n",
    "plt.title('Badge Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add percentages on bars\n",
    "for i, (badge, count) in enumerate(badges.items()):\n",
    "    pct = count / len(ranking_df) * 100\n",
    "    plt.text(i, count, f'{count:,}\\n({pct:.1f}%)', \n",
    "            ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77458b8",
   "metadata": {},
   "source": [
    "### 2.6. Text Length Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1047f90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text content length\n",
    "item_df['text_length'] = item_df['text_content'].str.len()\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(item_df['text_length'], bins=50, color='teal', alpha=0.7, edgecolor='black')\n",
    "plt.xlabel('Text Length (characters)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Product Description Length Distribution', fontweight='bold')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "# Box plot by category (top 10)\n",
    "text_by_cat = item_df[item_df['category'].isin(top_cats)][['category', 'text_length']]\n",
    "sns.boxplot(data=text_by_cat, x='category', y='text_length', palette='Set3')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel('Text Length')\n",
    "plt.title('Description Length by Category', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nText Length Statistics:\")\n",
    "print(item_df['text_length'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7dde842",
   "metadata": {},
   "source": [
    "## 3. Model Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c77947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training logs (if available)\n",
    "try:\n",
    "    import json\n",
    "    \n",
    "    # Assuming you saved training logs\n",
    "    with open('logs/training_history.json', 'r') as f:\n",
    "        history = json.load(f)\n",
    "    \n",
    "    # Plot Two-Tower training\n",
    "    if 'two_tower' in history:\n",
    "        tt_history = history['two_tower']\n",
    "        \n",
    "        plt.figure(figsize=(14, 5))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(tt_history['train_loss'], label='Train Loss', linewidth=2)\n",
    "        plt.plot(tt_history['val_loss'], label='Val Loss', linewidth=2)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Two-Tower Model - Training Loss', fontweight='bold')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(tt_history['recall_at_10'], label='Recall@10', linewidth=2)\n",
    "        plt.plot(tt_history['recall_at_50'], label='Recall@50', linewidth=2)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Recall')\n",
    "        plt.title('Two-Tower Model - Recall Metrics', fontweight='bold')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Plot MMoE training\n",
    "    if 'mmoe' in history:\n",
    "        mmoe_history = history['mmoe']\n",
    "        \n",
    "        plt.figure(figsize=(14, 5))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(mmoe_history['train_loss'], label='Train Loss', linewidth=2)\n",
    "        plt.plot(mmoe_history['val_loss'], label='Val Loss', linewidth=2)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('MMoE Model - Training Loss', fontweight='bold')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        tasks = ['Purchase', 'Quality', 'Price']\n",
    "        for task in tasks:\n",
    "            plt.plot(mmoe_history[f'auc_{task.lower()}'], label=f'{task} AUC', linewidth=2)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('AUC')\n",
    "        plt.title('MMoE Model - AUC per Task', fontweight='bold')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(\"Training logs not found. Run training first to generate logs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0edff5",
   "metadata": {},
   "source": [
    "## 4. Recommendation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0c669c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load recommendation results (if available)\n",
    "try:\n",
    "    results_dir = Path(\"results\")\n",
    "    result_files = list(results_dir.glob(\"recommendations_user_*.csv\"))\n",
    "    \n",
    "    if result_files:\n",
    "        print(f\"Found {len(result_files)} recommendation results\")\n",
    "        \n",
    "        # Load one example\n",
    "        sample_result = pd.read_csv(result_files[0])\n",
    "        \n",
    "        print(\"\\nSample Recommendations:\")\n",
    "        print(sample_result[['product_id', 'category', 'score', 'price', 'rating_average']].head(10))\n",
    "        \n",
    "        # Score distribution\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.hist(sample_result['score'], bins=30, color='purple', alpha=0.7, edgecolor='black')\n",
    "        plt.xlabel('Recommendation Score')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title('Score Distribution in Recommendations', fontweight='bold')\n",
    "        plt.show()\n",
    "        \n",
    "    else:\n",
    "        print(\"No recommendation results found. Run demo_inference.py first.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Could not load results: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed8a17e",
   "metadata": {},
   "source": [
    "## 5. Interactive Recommendation Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94735efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mini inference demo (requires models)\n",
    "try:\n",
    "    from demo_inference import RecommendationEngine\n",
    "    \n",
    "    # Initialize engine\n",
    "    print(\"Initializing Recommendation Engine...\")\n",
    "    engine = RecommendationEngine()\n",
    "    \n",
    "    # Test recommendation\n",
    "    user_id = 12345\n",
    "    recommendations = engine.recommend(user_id, top_n=10)\n",
    "    \n",
    "    print(f\"\\nTop 10 Recommendations for User {user_id}:\")\n",
    "    print(recommendations[['product_id', 'category', 'score', 'price']].to_string())\n",
    "    \n",
    "    # Visualize categories in recommendations\n",
    "    cat_counts = recommendations['category'].value_counts()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.pie(cat_counts, labels=cat_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "    plt.title(f'Category Distribution in Recommendations for User {user_id}', fontweight='bold')\n",
    "    plt.show()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Could not run inference demo: {e}\")\n",
    "    print(\"Make sure models are trained first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31c15e3",
   "metadata": {},
   "source": [
    "## 6. Export Analysis Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ed65de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary report\n",
    "report = f\"\"\"\n",
    "# RECOMMENDATION SYSTEM ANALYSIS REPORT\n",
    "\n",
    "## Dataset Statistics\n",
    "- Total Items: {len(item_df):,}\n",
    "- Total Categories: {item_df['category'].nunique():,}\n",
    "- Total Brands: {item_df['brand_id'].nunique():,}\n",
    "\n",
    "## Price Analysis\n",
    "- Average Price: {ranking_df['price'].mean():,.0f} VNÄ\n",
    "- Median Price: {ranking_df['price'].median():,.0f} VNÄ\n",
    "- Price Range: {ranking_df['price'].min():,.0f} - {ranking_df['price'].max():,.0f} VNÄ\n",
    "\n",
    "## Rating Analysis\n",
    "- Average Rating: {ranking_df['rating_average'].mean():.2f} / 5.0\n",
    "- Products with Reviews: {(ranking_df['review_count'] > 0).sum():,} ({(ranking_df['review_count'] > 0).mean()*100:.1f}%)\n",
    "\n",
    "## Discount Analysis\n",
    "- Products with Discount: {(ranking_df['discount_rate'] > 0).sum():,} ({(ranking_df['discount_rate'] > 0).mean()*100:.1f}%)\n",
    "- Average Discount: {ranking_df[ranking_df['discount_rate'] > 0]['discount_rate'].mean():.1f}%\n",
    "\n",
    "## Badge Statistics\n",
    "- Authentic: {ranking_df['is_authentic'].sum():,} ({ranking_df['is_authentic'].mean()*100:.1f}%)\n",
    "- FreeShip: {ranking_df['is_freeship'].sum():,} ({ranking_df['is_freeship'].mean()*100:.1f}%)\n",
    "- Return Policy: {ranking_df['has_return_policy'].sum():,} ({ranking_df['has_return_policy'].mean()*100:.1f}%)\n",
    "\n",
    "Generated: {pd.Timestamp.now()}\n",
    "\"\"\"\n",
    "\n",
    "# Save report\n",
    "with open('results/analysis_report.md', 'w', encoding='utf-8') as f:\n",
    "    f.write(report)\n",
    "\n",
    "print(\"âœ“ Analysis report saved to results/analysis_report.md\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233b8a0c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tikircm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
