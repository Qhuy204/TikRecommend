# ğŸ”§ Quick Fix Guide - Common Issues

## ğŸš¨ Your Current Issue

### Error: `FileNotFoundError: data/processed/item_features.csv`

**Cause:** Báº¡n Ä‘Ã£ cháº¡y `make interactions` nhÆ°ng chÆ°a cháº¡y `make preprocess` trÆ°á»›c Ä‘Ã³.

**Solution:**

```bash
# Option 1: Cháº¡y Ä‘Ãºng thá»© tá»±
make preprocess      # Táº¡o item_features.csv vÃ  ranking_features.csv
make interactions    # Táº¡o interactions.csv
make train-all       # Train models

# Option 2: Cháº¡y má»™t láº§n luÃ´n (recommended)
make pipeline        # Cháº¡y cáº£ 3 bÆ°á»›c trÃªn
make train-all       # Sau Ä‘Ã³ train
```

---

## ğŸ“‹ Correct Pipeline Order

```
Step 1: Download
  â†“
Step 2: Clean Data (remove errors)
  â†“
Step 3: Preprocess (extract features)  â† Báº N THIáº¾U BÆ¯á»šC NÃ€Y!
  â†“
Step 4: Extract Interactions
  â†“
Step 5: Train Models
```

### Commands theo thá»© tá»±:

```bash
# 1. Download dataset (náº¿u chÆ°a cÃ³)
make download

# 2. Clean data
make clean-data
# Output: data/clean/tiki_dataset_clean.jsonl

# 3. Preprocess features (IMPORTANT!)
make preprocess
# Output: 
#   - data/processed/item_features.csv
#   - data/processed/ranking_features.csv

# 4. Extract interactions
make interactions
# Output: data/processed/interactions.csv

# 5. Train models
make train-all

# 6. Demo
make demo-single
```

---

## âœ… Quick Check - Verify Files

```bash
# Check what files you have
python check_files.py

# Or manually check
ls -lh data/processed/
```

**Expected output:**
```
item_features.csv       # â† YOU NEED THIS
ranking_features.csv    # â† YOU NEED THIS
interactions.csv        # âœ“ YOU HAVE THIS
```

---

## ğŸ¯ Fast Fix - One Command

Náº¿u báº¡n muá»‘n cháº¡y láº¡i tá»« Ä‘áº§u:

```bash
# Clean everything and start fresh
make clean
make pipeline    # This runs: clean-data â†’ preprocess â†’ interactions
make train-all   # Train both models
```

---

## ğŸ” Debugging Steps

### 1. Check if clean data exists

```bash
ls -lh data/clean/tiki_dataset_clean.jsonl
```

**If missing:**
```bash
make clean-data
```

### 2. Check if preprocessed features exist

```bash
ls -lh data/processed/item_features.csv
ls -lh data/processed/ranking_features.csv
```

**If missing:**
```bash
make preprocess
```

### 3. Check if interactions exist

```bash
ls -lh data/processed/interactions.csv
```

**If missing:**
```bash
make interactions
```

### 4. Now train

```bash
make train-all
```

---

## ğŸ“Š Understanding the Files

### `item_features.csv` (for Two-Tower Model)
Columns:
- `product_id`: ID sáº£n pháº©m
- `text_content`: Text Ä‘Ã£ clean (name + description + specs)
- `category`: Danh má»¥c
- `brand_id`: ID thÆ°Æ¡ng hiá»‡u

**Created by:** `make preprocess`

### `ranking_features.csv` (for MMoE Model)
Columns:
- `product_id`, `price`, `list_price`, `discount_rate`
- `rating_average`, `review_count`, `quantity_sold`
- `seller_id`, `is_authentic`, `is_freeship`, `has_return_policy`, `is_available`

**Created by:** `make preprocess`

### `interactions.csv` (for Training)
Columns:
- `user_id`: Customer ID
- `product_id`: Product ID
- `rating`: Rating score
- `timestamp`: Review time
- `is_good_quality`: Quality signal (0/1)
- `is_good_price`: Price signal (0/1)

**Created by:** `make interactions`

---

## ğŸš€ Full Workflow - Start to Finish

```bash
# Step 1: Setup
git clone <repo>
cd recommendation-system
make install

# Step 2: Get data
make download

# Step 3: Process data (IMPORTANT - ALL 3 FILES)
make pipeline
# This creates:
#   âœ“ data/clean/tiki_dataset_clean.jsonl
#   âœ“ data/processed/item_features.csv
#   âœ“ data/processed/ranking_features.csv  
#   âœ“ data/processed/interactions.csv

# Step 4: Verify files
python check_files.py
# Should show all âœ…

# Step 5: Train
make train-all
# This trains:
#   âœ“ models/two_tower_best.pt
#   âœ“ models/mmoe_best.pt

# Step 6: Test
make demo-single
```

---

## âš¡ Time Estimates

With full dataset (~125k products, 1.3M reviews):

| Step | Time | Output |
|------|------|--------|
| `make download` | 10-30 min | Raw JSONL |
| `make clean-data` | 2 min | Clean JSONL |
| `make preprocess` | 10-15 min | Features CSV |
| `make interactions` | 1-2 min | Interactions CSV |
| `make train-two-tower` | 30-60 min | Two-Tower model |
| `make train-mmoe` | 10-20 min | MMoE model |
| **TOTAL** | **~1-2 hours** | Full system |

With sample (1000 products):

```bash
make preprocess-sample  # ~1 min
make train-quick        # ~5 min
make demo-single        # <1 min
```

---

## ğŸ› Other Common Errors

### Error: "CUDA out of memory"

**Solution:**
```bash
# Reduce batch size
python training_scripts.py --batch_size 32

# Or use CPU
export CUDA_VISIBLE_DEVICES=-1
python training_scripts.py --batch_size 64
```

### Error: "PhoBERT not found"

**Solution:**
```bash
# Download manually first
python -c "from transformers import AutoModel, AutoTokenizer; \
           AutoModel.from_pretrained('vinai/phobert-base'); \
           AutoTokenizer.from_pretrained('vinai/phobert-base')"
```

### Error: "No module named 'recommendation_system'"

**Solution:**
```bash
# Make sure you're in the right directory
cd recommendation-system

# Check if file exists
ls recommendation_system.py
```

---

## ğŸ“ Still Having Issues?

1. **Check files:**
   ```bash
   python check_files.py
   ```

2. **Clean and restart:**
   ```bash
   make clean
   make pipeline
   ```

3. **Check logs:**
   ```bash
   make debug
   ```

4. **Verify dataset:**
   ```bash
   head -n 1 data/clean/tiki_dataset_clean.jsonl | python -m json.tool
   ```

---

## âœ… Success Checklist

Before training:
- [ ] âœ… `data/clean/tiki_dataset_clean.jsonl` exists
- [ ] âœ… `data/processed/item_features.csv` exists
- [ ] âœ… `data/processed/ranking_features.csv` exists
- [ ] âœ… `data/processed/interactions.csv` exists

After training:
- [ ] âœ… `models/two_tower_best.pt` exists
- [ ] âœ… `models/mmoe_best.pt` exists

Ready to demo:
- [ ] âœ… All above files exist
- [ ] âœ… `python check_files.py` shows all green

---

**Now you can run:**
```bash
make demo-single
```

Good luck! ğŸš€
